---
title: "Epigenomics"
author: "S. Quiñones, J. Rojas, X. Díaz"
date: "3/24/2022"
output: 
  html_document:
    toc: yes
  pdf_document:
    toc: yes
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

Until now, three broad classes of regulatory elements that control gene
expression have been described: promoters, enhancers and boundary
elements. This elements switch genes on and off in response to intrinsic
and external signals (Higgs.D, 2020).

When activated, enhancers appear to make physical contact with the
promoters that they control. Some times enhancers are somewhat far from
their respective promoters, so DNA-looping is required in order to make
this contact possible. This promoter-enhancer interactions are not
necessarily done in a 1:1 proportion; since one enhancer can regulate
multiple promoters, and a single promoter can be regulated by multiple
enhancers; making these promoter-enhancer interactions even more
complex.

Our assay is to compare enrichment of histone modification H3K4me3
(which is generally associated with active promoters and transcribed
regions), in promoter regions with Hi-C fragments (which most likely
will represent enhancers), obtained from inflammatory macrophages. Then
we describe which transcription factors are enriched in both sequence
sets (promoters and fragments).

# Analysis

## Data Description

-Species: Homo Sapiens -Cell type: macrophages -Subject: adult female

## Defining a histone of interest

To perform our analyisis, it is important to select carefully a target
histone. In this case, we have chosen H3K4me3. The biological reason for
doing so is that H3K4me3 has been reported associated to increased
promoter activity and transcription. Therefore, whilst performing our
analysis, we expect this histone to have an increased activity in
promoters respective to enhancers.

##Is there Histone enrichment comparing enhancers and fragments? To
detect enrichment for the histone H3K4me3 we will use the command
computematrix from the module "deeptools" for computing the signal
distribution relative to a certain point of the promoter or enhancer (
reference-point mode). For this, we need two files: the bed , which is a
file containing all the positions of interest, and a bigwig, which is a
file containing signal scores of specific regions for the histone of
interest.

### Bed files proccessing

To obtain the bed files, we downloaded a zip with the following command:

wget
<https://www.cell.com/cms/10.1016/j.cell.2016.09.037/attachment/5bc79f6f-1b69-4192-8cb8-4247cc2e0f39/mmc4.zip>

```{r eval=FALSE, echo=TRUE}
wget https://www.cell.com/cms/10.1016/j.cell.2016.09.037/attachment/5bc79f6f-1b69-4192-8cb8-4247cc2e0f39/mmc4.zip

wget is a networking command-line tool that lets you download files. You only need to give it the URL of the file of interest.
```

Then, we focused on ActivePromoterEnhancerLinks.tsv, which is a file
containing interactions between putative promoters and enhancers. It
also contains in which cell types a specific interaction occurred and
the genomic regions involved.

As we said before, we will be focused on Mac1 (inflammatory
macrophages), so, as first step, we need to filter the
ActivePromoterEnhancerLinks.tsv by the word Mac1. For this, we ran the
following command:

```{r eval=FALSE, echo=TRUE}
grep Mac1 ActivePromoterEnhancerLinks.cleaned.tsv > M1.tsv

The structure grep <word> <filename> is used to search any line that contains the word in filename. 


```

Once we have filtered the previous file, we can continue.

A bed file is mainly constituted by the chromosome number and the start
and end of the region of interest. So, to obtain the bed files we need
for further analysis, we ran the following command:

```{r eval=FALSE, echo=TRUE}
awk '{print $1,$2,$3}' M1.tsv > Promoters_data_paper.bed

awk '{print $5,$6,$7}' M1.tsv > Enhancers_data_paper.bed

Awk can be used to search for a specific word when we use /word/. When we are adding '{print $1,$2,$3}', we are saying that we want to print the columns 1,2,3 from the file M1.tsv and save them in the new file Promoters_data_paper.bed.

```

### GRCh37 to GRCh38

Given that the positions contained in the bed files are in the version
GRCh37, we need to transform this data to the version GRCh38. To do so,
we used the following page: <https://genome.ucsc.edu/cgi-bin/hgLiftOver>

In this page, we need to upload our bed files and indicate the original
version of our data and the version to which we want to transform them.
What the web page is actually doing is running the following command:

```{r eval=FALSE, echo=TRUE}

liftOver input.bed hg18ToHg19.over.chain.gz output.bed unlifted.bed

liftOver from UCSC is mainly used for converting genome positions from one genome assembly to another. This command requires a chain file, which contains the liftOver data needed to convert hgX 
 coordinates to hgY, and a unlifted.bed, which will contain all genome positions that cannot be lifted.

```

![](./Imagen_UCSC.png)

Once the above is done, we obtain the following files:

```{r eval=FALSE, echo=TRUE}
Promoters_data_paper_38.bed
Enhancers_data_paper_38.bed

```

### Downloading the BigWigs

Now we have obtained the final bed files, we can proceed to download the
BigWigs with the following commands:

```{r eval=FALSE, echo=TRUE}
(wget http://ftp.ebi.ac.uk/pub/databases/blueprint/data/homo_sapiens/GRCh38/venous_blood/S001MJ/inflammatory_macrophage/ChIP-Seq/NCMLS/S001MJH1.ERX300707.H3K4me3.bwa.GRCh38.20150528.bw ; wget http://ftp.ebi.ac.uk/pub/databases/blueprint/data/homo_sapiens/GRCh38/venous_blood/S001S7/inflammatory_macrophage/ChIP-Seq/NCMLS/S001S7H2.ERX300682.H3K4me3.bwa.GRCh38.20150528.bw ; wget http://ftp.ebi.ac.uk/pub/databases/blueprint/data/homo_sapiens/GRCh38/venous_blood/S0022I/inflammatory_macrophage/ChIP-Seq/NCMLS/S0022IH2.ERX300720.H3K4me3.bwa.GRCh38.20150528.bw ; wget http://ftp.ebi.ac.uk/pub/databases/blueprint/data/homo_sapiens/GRCh38/venous_blood/S001MJ/inflammatory_macrophage/ChIP-Seq/NCMLS/S001MJH1.ERX300715.Input.bwa.GRCh38.20150528.bw ; wget http://ftp.ebi.ac.uk/pub/databases/blueprint/data/homo_sapiens/GRCh38/venous_blood/S001S7/inflammatory_macrophage/ChIP-Seq/NCMLS/S001S7H2.ERX300716.Input.bwa.GRCh38.20150528.bw
wget http://ftp.ebi.ac.uk/pub/databases/blueprint/data/homo_sapiens/GRCh38/venous_blood/S0022I/inflammatory_macrophage/ChIP-Seq/NCMLS/S0022IH2.ERX300717.Input.bwa.GRCh38.20150528.bw)


```

We decided to obtain 3 replicates as in the paper. The samples have the
following features:

\*S0022I : Sample from a 50 - 55 years old female. Cell-type
inflammatory macrophage and tissue-type venous blood.

\*S001S7 : Sample from a 40 - 45 years old female. Cell-type
inflammatory macrophage and tissue-type venous blood.

\*S001MJ : Sample from a 55 - 60 years old male Cell-type inflammatory
macrophage and tissue-type venous blood.

Both cell type and tissue type are the same as in the paper, also the
cell isolation methods used by the paper are the same used in blueprint.

### BigWigs proccesing

The pipeline to transform the fasta files into BigWigs is the following:

#### Mapping

The mapping was carried out using bwa 0.7.7 to human genome GRCh38
reference. The reference file can be found in:
<ftp://ftp.ebi.ac.uk/pub/databases/blueprint/reference/20150407_reference_files>

Command line used:

```{r eval=FALSE, echo=TRUE}

bwa aln -q 5 grch38.fa input.fastq.gz > intermediate.sai

-bwa is a software package for mapping low-divergent sequences against a large reference genome, such as the human genome. Bwa can use different alignment methods such as aln and mem.
  
-aln is a alignment method that is prefered for short reads, as the case, other methods such as mem have a better performance with reads longer than 70bp.

-grch38.fa is the fasta file containing the index

-input.fastq.gz are the chip-seq read to aling.

-intermediate.sai is the output, containing the suffix array coordinate of all short reads loaded in.

 bwa samse -r "read group information" grch38.fa intermediate.sai input.fastq.gz | samtools view -bS - > output.bam
 
-samse uses the .sai file to generate a SAM file 
 
-the -r option specifies the read group in a format like ‘@RG\tID:foo\tSM:bar’
 
-grch38.fa is the fasta file containing the index
 
-intermediat.sai is the file containing the suffix array coordinate of all short reads loaded in.
 
-input.fastq.gz are the chip-seq read to aling.
 
samse generates a sam file as ouput.

-samtools view With no options or regions specified, prints all alignments in the specified input alignment file (in SAM, BAM, or CRAM format) to standard output in sample.

-b option is used to indicate that we want the output to be in BAM format.

-S option is used to ignore for compatibility with previous samtools versions.

At the end, we obtain a BAM file.


```

#### BAM files are sorted and then duplicates marked using picard:

```{r eval=FALSE, echo=TRUE}
java -Xmx2048m -jar picard/SortSam.jar INPUT=input.bam OUTPUT=output.bam SORT_ORDER=coordinate VALIDATION_STRINGENCY=SILENT

-Xmx2048m this argument specifies the maximum memory allocation pool for a Java Virtual Machine (JVM), in this case, it is of 2048 mb.

-picard/SortSam.jar specifies the tool that will be used.

-INPUT specifies the input file.

-OUTPUT specifies the output file name.

-SORT_ORDER specifies that the bam file wil be sorted by coordinates.

-VALIDATION_STRINGENCY.Setting stringency to SILENT can improve performance when processing a BAM file in which variable-length data (read, qualities, tags) do not otherwise need to be decoded.
```

```{r eval=FALSE, echo=TRUE}

java -Xmx2048m -jar picard/MarkDuplicates.jar INPUT=input.bam OUTPUT=output.bam METRICS_FILE=output.dup_metrics REMOVE_DUPLICATES=false ASSUME_SORTED=true VALIDATION_STRINGENCY=SILENT

-picard/MarkDuplicates.jar indicates the tool that will be used.In this case, this tool locates and tags duplicate reads in a BAM or SAM file.

-METRICS_FILE specifies the file to write duplication metrics to.

-REMOVE_DUPLICATES.If true do not write duplicates to the output file instead of writing them with appropriate flags set.

-ASSUME_SORTED. If true, assume that the input file is coordinate sorted even if the header says otherwise. 

-VALIDATION_STRINGENCY.Setting stringency to SILENT can improve performance when processing a BAM file in which variable-length data (read, qualities, tags) do not otherwise need to be decoded.

```

#### Filtering

The output bam file was then filtered to remove unmapped reads and reads
with Mapping Quality less than 5.

Command line used:

```{r eval=FALSE, echo=TRUE}
samtools view -b -F 4 -q 5 input.bam > intermediate.output.bam

-b specifies the output to be in bam format.

-F specifies that the alignments with the flag 4 will be excluded. In this case, the unmapped reads will be excluded.

-q option says that only reads with mapping quality of at least 5 will be included.


```

The intermediate output bam file was then filtered to remove PCR or
optical duplicate reads

Command line used:

```{r eval=FALSE, echo=TRUE}

samtools view -b -F 1024 intermediate.output.bam > output.bam

-b specifies the output to be in bam format.

-F specifies that the alignments with the flag 1024 will be excluded. In this case, if the read is PCR or optical duplicate will be excluded.


```

#### Modelling Fragment Size

The fragment size is modelled using the PhantomPeakQualTools R script:

```{r eval=FALSE, echo=TRUE}
run_spp.R -c=output.bam -rf -out=params.out

-c= indicates the full path of the bam file.

-rf do the following: if plot or rdata or narrowPeak file exists replace it. If not used then the run is aborted if the plot or Rdata or narrowPeak file exists.
  
-out= append peakshift result to a file. 

```

#### Peak Calling

MACS2 (2.0.10.20131216) is used for peak calling with the fragment size
predicted by PhantomPeakQualTools. They used both the standard method of
running and the -broad flag depending on the mark in question.

Command line used:

```{r eval=FALSE, echo=TRUE}
macs2 callpeak -t chip.bam -n a_sensible_name --gsize hs -c input.bam --nomodel --shiftsize=half_fragment_size --broad

macs2 callpeak -t chip.bam -n a_sensible_name --gsize hs -c input.bam --nomodel --shiftsize=half_fragment_size

-t specifies the treatment file.

-n specifies the string name that macs will use to create the ouput files.

-gsize specifies the effective genome size. In this case it is of 2.7e9.

-c specifies the control file.

-nomodel. While on, MACS will bypass building the shifting model.

-shiftsize specifies the fragment size.

-broad. When this flag is on, MACS will try to composite broad regions in BED12 ( a gene-model-like format ) by putting nearby highly enriched regions into a broad region with loose cutoff. 
```

The marks where -broad were used are

    H3K27me3
    H3K36me3
    H3K9me3
    H3K4me1

The marks where -broad is omitted are

    H3K27ac
    H3K4me3
    H3K9/14ac
    H2A.Zac

#### Wiggle plots

Signal plots are produced using align2RawSignal using the fragment size
predicted by PhantomPeakQualTools:

```{r eval=FALSE, echo=TRUE}

align2rawsignal -i=chip.bam -of=bg -o=chip.bg -l fragment_size -s=/path/to/fasta_files -u=/path/to/umap_files

align2rawsignal converts tagAlign/BAM files into normalized signal.

-i specifies the input bam files.

-of specifies the output signal file format. In this case, it is bedGraph 

-o specifies the full path and name of output signal file.

-l specifies the fragment length.

-s specifies the full path and name of output signal file.

-u specifies the full path to directory containing binary mappability tracks.

```

### BigWigs normalization and merging

Given that Wiggler (align2rawsignal) does not implement
input-DNA/control corrections, we decided to normalize our BigWigs files
by the input with the tool bigwigCompare from deeptools. The
normalization was carried out using the log2 of the ratio of both
treatment and input file.

```{r eval=FALSE, echo=TRUE}
bigwigCompare -b1 S001MJH1.ERX300707.H3K4me3.bwa.GRCh38.20150528.bw -b2 S001MJH1.ERX300715.Input.bwa.GRCh38.20150528.bw -o S001MJH1.ERX300715.H3K4me3.normalized.bwa.GRCh38.20150528.bw

-b1 specifies the filename for the treatment.

-b2 specifies the filename for the control.

-o specifies the output filename. BigWig format is set as default.

It is importat to point out that we ran this command for the 3 replicates separately, using the respectives treatment and control files.

```

Once the normalization was carried out, we proceeded to merge the
normalized files. files-merging was carried out assuming that the
replicates are similar enough, in fact, other analysis must be done
before doing this, but this would take extra-time, so we decided to
proceed this way.

Merging process was done with the following command:

```{r eval=FALSE, echo=TRUE}
bigWigMerge S001MJH1.ERX300715.H3K4me3.normalized.bwa.GRCh38.20150528.bw S001S7H2.ERX300716.H3K4me3.normalized.bwa.GRCh38.20150528.bw S0022IH2.ERX300717.H3K4me3.normalized.GRCh38.20150528.bw merge.normalized.H3K4me3.bedGraph

The first three files are our normalized BigWigs. The last filename is the one that the output will have.


```

Now we need to convert the merged bedGraph file to a BigWig. To do so,
we first sorted the bedGraph file given the recommendations read in
biostars.

```{r eval=FALSE, echo=TRUE}

sort -k1,1 -k2,2n merge.normalized.H3K4me3.bedGraph > merge.normalized.sorted.H3K4me3.bedGraph

-k specifies the columns to be sorted.

The -k1,1 notation sets the start and stop limits of the first sort key to the first field.

-n indicates that the columns will be sorted numerically.

bedGraphToBigWig merge.normalized.sorted.H3K4me3.bedGraph GRCh38_EBV.chrom.sizes.tsv merge.normalized.sorted.H3K4me3.bw

This command needs the input bedGraph file, the cromosome sizes file and the output filename.
 
The file GRCh38_EBV.chrom.sizes.tsv contains the sizes of all the chromosomes. Ee downloaded it from: https://www.encodeproject.org/files/GRCh38_EBV.chrom.sizes/


```

Now we are ready to run computematrix for both BigWigs

```{r eval=FALSE, echo=TRUE}

 computeMatrix reference-point -S merge.normalized.sorted.H3K4me3.bw -R ../Promoters_data_paper_38.bed --referencePoint center -a 4000 -b 4000 -out matrix_Promoters_H3K4me3_normalized_matrix.tab.gz

This tool calculates scores per genome regions and prepares an intermediate file that can be used with "plotHeatmap".

-Reference-point refers to a position within the Bed file(e.g., the starting point). In this mode, only those genomic positions before (upstream) and/or after (downstream) of the reference point will be plotted. We used, as first approach, the center of the regions as reference point. The distance upstream and dowstream from the reference point will be of 4000 bp in both cases.

-S specifies the BigWig file containing the scores to be plotted.

-R specifies the file containing the regions to plot.

-out specifies the output name of the matrix.

```

Now we have the scores per promoters and enhancers regions in two
independent matrix. We will plot this information with the command
"plotHeatmap" as following:

```{r eval=FALSE, echo=TRUE}

 plotHeatmap -m matrix_Promoters_H3K4me3_normalized_matrix.tab.gz -out H3K4me3_Promoters_normalized.png --heatmapHeight 15 --refPointLabel Promoter.center --regionsLabel Promoters --plotTitle ' H3K4me3 signal - Promoters'

This tool creates a heatmap for scores associated with genomic regions

-m specifes the matrix file from the computeMatrix tool.

-out specifies the file name to save the image to. 

-heatmapHeight specifies the plot height in cm.

-refPointLabel specifies the label shown in the plot for the reference-point.

-regionsLabel specifies the labels for the regions plotted in the heatmap.

-plotTitle specifies the title of the plot to be printed on top of the generated image.
```

We obtained the following two heatmaps:

![](./fused.png)

As we can see, there is an enrichment for the histone H3K4me3 in
promoters since all the promoters regions analysed here are above 2, in
contrast, the enhancers regions analysed exhibit scores below 1.5.

### Statiscal analysis

To test whether there is a significant enrichment for histone H3K4me3 in
promoter regions, we will perform a mean comparison test between both
matrix. To do this, we first need to test our data for normality in
order to decide for one approach or another.

To test normality, we will use qqplots and a Jarque-Bera test (which
performs well with big samples). In order to carry out this approach, we
need to reduce the dimensionality of our data, to do so, we decided to
calculate the mean of each matrix row. After doing so, we obtained an
array containing the means of the normalized signal scores for each
promoter and enhancer regions analyzed.

From now on, when we mention Promoters or Enhancers data, we mean the
respective arrays containing the averages for each row from both
Promoters and Enhancers matrix.

The following R script will perform what we have said:

```{r}
setwd("~/BioinfoII_epig")

#Loading data

Promoters_data<-read.delim("matrix_Promoters_H3K4me3_normalized_matrix.tab.gz", header = FALSE, sep = "\t",quote = "")

Enhancers_data<-read.delim("matrix_Enhancers_H3K4me3_normalized_matrix.tab.gz", header = FALSE, sep = "\t",quote = "")

# Converting NAs to 0

Promoters_data[is.na(Promoters_data)] = 0 
Enhancers_data[is.na(Enhancers_data)] = 0

# Removing header

Promoters_data<-Promoters_data[-1,]
Enhancers_data<-Enhancers_data[-1,]

# Removing useless columns 

Promoters_data<-Promoters_data[,-c(1,2,3,4,5,6)]
Enhancers_data<-Enhancers_data[,-c(1,2,3,4,5,6)]

# Calculating the mean for each row in the matrix

Promoters_row_means <- data.frame(ROW_MEANS=rowMeans(Promoters_data))
Enhancers_row_means <- data.frame(ROW_MEANS=rowMeans(Enhancers_data))

# Generating the qqplot
qqnorm(Promoters_row_means$ROW_MEANS, pch = 19, col = "blue",main="Promoters")
qqline(Promoters_row_means$ROW_MEANS)

qqnorm(Enhancers_row_means$ROW_MEANS, pch = 19, col = "red",main="Enhancers")
qqline(Enhancers_row_means$ROW_MEANS)

# Jaquera-Bera test
library("tseries")
jarque.bera.test(x=Promoters_row_means$ROW_MEANS)
jarque.bera.test(x=Enhancers_row_means$ROW_MEANS)

```

From qqplots of both Enhancers and Promoters we conclude that these data
are not normal since some dots in both plots do not follow the straight
line.

From the Jarque-Bera test, we conclude that both Promoters and Enhancers
row means are not normal since both obtain a p-value lower than 2.2e-16.

Given the above, we will use a non-parametric test such as the Wilcoxon
test to perform the mean comparison analysis between Enhancers and
Promoters.

```{r}
#Wilcoxon test
wilcox.test(Promoters_row_means$ROW_MEANS,Enhancers_row_means$ROW_MEANS,alternative = "two.sided",mu=0, paired=F, conf.int = T, conf.level = 0.99)
```

The Wilcoxon test returned a p-value lower than 2.2e-16, proving that
there is a significant difference between the means of both Promoters
and Enhancers data. The test returned a 99% confidence interval that
goes from 1.773477 to 1.815496, so, given that the sign of the interval
is positive, this proves that mean of the Promoters data is greater than
the mean of the Enhancers data, proving that there is a significant
enrichment for the histone modification H3K4m3 in promoter regions as
expected.

## FastQ Pipeline into BigWig

To create the bigwig files used in this analysis, the fastq files
obtained through sequencing were concatenated if more than one was
produced per biological replicate. These were all submitted to quality
controls; specifically, read length should have a minimum length of
50bp. Then, either the unique or concatenated files were aligned into
bam files. A quality control was then performed on the resulting bam
files and then filtered to make a second bam file according to quality.

## ¿What transcription factor is enriched in both promoters and enhancers?

To compare enrichment present in both data sets we need a .bed file that
contains the sequences that are enriched for both promoters and
enhancers. We got this file by using the bedops program, it is a tool
used to find relationships between two or more genomic datasets. In this
case we used the --intersect function, which allows us to out put a .bed
file that contains the regions that are common in both input files, in
other words it gives the intersection of genomic space of two .bed
files. This input .bed files must be sorted, which we all ready did in
previous steps.

```{eval =F}
module load bedops/2.4.20
bedops --intersect Enhancers_data_paper_38.bed Promoters_data_paper_38.bed > Enh_Pro_isec38.bed
```

Because both input files are sorted, the output file will be sorted too,
but in case it wasn't sorted we could run the following (this function
was previously explained):

```{eval =F}
module load bedtools/2.26
sortBed -i Enh_Pro_isec38.bed > Sorted_Enh_Pro_isec38.bed
```

In the following link we uploaded the Sorted_Enh_Pro_38.bed file to
fetch the sequences found in both promoters and enhancers.
<http://rsat.sb-roscoff.fr/fetch-sequences_form.php> As settings we used
: - Geneome: hg38 - Header format UCSC - Reference from which the
sequence should de fetched: Segment

This gave us a .bed file with the Genomic coordinates, a .fasta file
with the fetched sequences, and a .txt file with the information of the
submitted job.

We downloaded the .fasta file to the cluster

```{eval =F}
wget -O fetched_seq2.fasta http://rsat.sb-roscoff.fr//tmp/apache/2022/04/12/Sorted_Enh_Pro_38_jcrt_20220412_210953.fasta
```

## Non redundant Jaspar colection

We retrieved a non redundant JASPAR collection of characterized TFBS so
that our analysis is not biases by overlapping TFBS. If we used the
redundant JASPAR collection, this would make us considered some regions
multiple times in our analysis, which is is not ideal for solely
identifying the TFBS present in both promoters and enhancers in our
data.

To do this we used the CORE Jaspar collection and filtered it to down to
Homo sapiens latest version profiles that where optained with Chip-seq.
233 profiles where found as shown in the following link:
<https://jaspar.genereg.net/search?q=&collection=CORE&tax_group=all&tax_id=9606&type=ChIP-seq&class=all&family=all&version=latest>

Next we 'added to cart' all profiles found. After setting the download
option for all this profiles as 'combined' and matrix format 'MEME' (as
this is the format supported by the program 'matrix-scan' that we will
be using along with R-sat for pattern matching), the Jaspar web-site
gives a link to download the matrices. We download this to the cluster.

``` {eval="F"}
wget -O JASPAR_matrices_meme.txt http://jaspar.genereg.net/temp/20220419044948_JASPAR2022_combined_matrices_29625_meme.txt
```

## Permutations as control sequences

For the control, we downloaded permuted versions of the 233 profiles
found in Jaspar so that we have better chances of the results from the
pattern matching not being by chance. For the permute settings we used
type: 'within each matrix' (so that we are not biased towards the
nucleotide abundance of certain TFBS regions), and format: MEME. We
download the permuted matrices to the cluster.

``` {eval="F"}
wget -O JASPAR_permatrices_meme.txt http://jaspar.genereg.net/temp/20220419045401_permuted_matrices_29625.txt
```

Note: The links provided by JASPAR to download the generated files last
up to 5 days.

## Pattern Matching Form the RSAT documentation we decided to use the
'matrix-scan' program for pattern matching as it allows multiple
sequences and PSSM as input, as well as pre-calibrated markov models and
customized background models. In this case we used the permuted matrices
as background model as this plays with the nucleotide frequency in a
certain region and will be a good indicator for the matrix-scan to
statistically test how likely it is for a region with this nucleotide
frequencies to match the TFBS by chance or because it could be a real
TFBS.

``` {eval="F"}
module load rsat/8sep2021

matrix-scan -m JASPAR_matrices_meme.txt -matrix_format meme -i fetched_seq2.fasta -bgfile JASPAR_permatrices_meme.txt -bg_format meme -o matrix_scan2
```

-m \<matrces_file_meme.txt> indicates the name of the matices file
-matrix_format meme indicates the matrices file is in meme format -i
\<sequences.fasta> indicates the name of the file with the sequences it
will use to scan the matrices with -bgfile \<backgroung_model.txt>
indicates the name of the file with the background model -bg_format meme
indicates the background model file is in meme format -o <outout_file>
indicates the name of the output file it will write

Note: This function might take several days to run

The output file is tab-delimited with one row per match, it contains the
following information:

-seq_id: Name of the sequence, in this case it has a
hg38_chr<n><start_pos><end_pos>\_+ format -ft_type: it takes values of
'limit' or 'site', with site indicating the match is at the TFBS.
-ft_name: Name of the PWM corresponding to this hit -strand: Indicates
in which strand was the hit, 'D' is for direct strand and 'R' is for
reverse strand. -start: Position of the first hit relative to the
fetched seq, with the first nucleotide being -1. -end: Position of the
last hit relative to the fetched seq, with the first nucleotide being
-1. -sequence: Nucleotide sequence of the potential binding site.
-weight: Weight of a sequence segment (Ws) calculated as: $$
Ws= log[P(S|M)/P(S|B)]
$$ Where: S : Sequence segment M : PSSM B : Background model matrix
Note: the program uses natural logarithms

## Finding significant TFBS To retrieve the most significant TFBS matched
by our fetched sequences (that represent the genomic regions where
H3K4me3 binds in both promoters and enhancers); we first look at the
weight scores given by the matrix-scan program and the length of the
matched sequences.

Here we are looking for the biggest weight scores. Because of how the
weight is calculated, then the bigger the weight scores, the more
significant the probability of the matched sequences is to be a real
TFBS. We also look for fairly long sequences, as short matching
sequences will easily fit into random sequences just because they are
short.

### Statistical Test

To know what our weight score threshold should be, we performed a
Bonferroni statistical test, which is used to reduce false positives
when dealing with multiple comparatives, in this way we aim to reduce
the significance of false positives in our results:

```{r,eval=TRUE}
#significance level for a single hypothesis test
ai = 0.05
#total number of tests
n = 146697729 

# Setting the FWER to the selected significance weight for a single hypothesis

af= ai / n
af

# We know that the weight is calculated according to the formula:
# Ws= log[P(S|M)/P(S|B)]
# Since we have set our significance at af for each test, we substitute P(S|B) as af and P(S|M)<1
# Ws = log[<1/af] and finally: Ws < log [1/af] in this way, we know that by selecting this value our probability of having one false positive will be lower than our significance value.
weight = log(1/af)
weight


```

Because of how the weight is calculated, then the bigger the weight
scores, the more significant the probability of the matched sequences is
to be a real TFBS. According to the Bonferroni test we performed, a
weight score threshold of 22 should be enoght to rule out enough false
positives from the matrix-scan output. We also look for fairly long
sequences, as short matching sequences will easily fit into random
sequences just because they are short.

To fetch long sequences (more than 20 nucleotides) and high weight
scores (grater than 22): Note: the length and weight scores are
arbitrary.

``` {eval="F"}
awk '{if(($6 - $5)> 20 && $8>22) print ($3)}' matrix_scan2 | sort | uniq > ID_mat.txt

#to see how many significant TFBS where found:
wc -l ID_mat.txt
#output
16
```

With this parameters 16 significant TFBS where found for our fetched
sequences.

To fetch the name of the TFBS for each matrix match that passed our
threshold:

```{r, eval=F}
grep -f ID_mat.txt JASPAR_matrices_meme.txt | cut -d "." -f 4 >> TF_name.txt

less TF_name.txt
#output
REST
ESR1
TP63
IRF1
ZNF140
ZNF382
ZNF675
ZNF8
NFIB
ZFP42
ZNF16
SPI1
CTCF
CTCF
ZNF320
ZNF324
```

### TFBS Function

Looking at JASPAR's database we can have an idea of the function of this
TF: REST -> C2H2 zinc finger factors ESR1 -> Nuclear receptors with C4
zinc fingers TP63 -> p53 domain factors IRF1 -> Tryptophan cluster
factors ZNF140 -> C2H2 zinc finger factors\
ZNF382 -> C2H2 zinc finger factors ZNF675 -> C2H2 zinc finger factors
ZNF8 -> C2H2 zinc finger factors NFIB -> SMAD/NF-1 DNA-binding domain
factors ZFP42 -> C2H2 zinc finger factors ZNF16 -> C2H2 zinc finger
factors SPI1 -> Tryptophan cluster factors CTCF -> C2H2 zinc finger
factors CTCF -> C2H2 zinc finger factors ZNF320 -> C2H2 zinc finger
factors ZNF324 -> C2H2 zinc finger factors \*Note: we where able to find
further information for each gene in the Gene Cards database:
<https://www.genecards.org/>

## Conclusion

Firstly, there is significantly more enrichment for the histone
modification H3K4m3 in promoter regions than in enhancer regions for
Mcrophage from human samples.

Secondly, we found 16 significantly enriched TFBS that are present both
in promoters and enhancers of this Macrophage samples. The proteins
associated with this TFBS are mostly zinc fingers that bind directly to
DNA to either mediate chromatin structure or are involved in other gene
activation or repression activities.

# Sources

    https://hgdownload.cse.ucsc.edu/goldenpath/hg19/liftOver/
    liftOver: A set of of "cadenas" must be downloaded from the UCSC database. 

Monocyte data used
<http://ftp.ebi.ac.uk/pub/databases/blueprint/data/homo_sapiens/GRCh38/venous_blood/Primary_monocytes_Donor_E/monocyte_-_None/ChIP-Seq/NCMLS/S01E11H1.ERX1484944.H3K4me3.bwa.GRCh38.20160701.bed.gz>
<http://ftp.ebi.ac.uk/pub/databases/blueprint/data/homo_sapiens/GRCh38/venous_blood/Primary_monocytes_Donor_C/monocyte_-_None/ChIP-Seq/NCMLS/S01BM8H1.ERX1484934.H3K4me3.bwa.GRCh38.20160527.bed.gz>

##References and Programs used

Author. (year) Title. Journal editon. pp-pp.

Higgs, D.R. Enhancer--promoter interactions and transcription. Nat Genet
52, 470--471 (2020). <https://doi.org/10.1038/s41588-020-0620-7>

Biola M. Javierre, Oliver S. Burren, Steven P. Wilder, ..., Chris
Wallace, Mikhail Spivakov, Peter Fraser (2016). Lineage-Specific Genome
Architecture Links Enhancers and Non-coding Disease Variants to Target
Gene Promoters. Cell 167, 1369-1384.

Thomas-Chollier, M., Sand, O., Turatsinze, J. V., Janky, R., Defrance,
M., Vervisch, E., Brohée, S., & van Helden, J. (2008). RSAT: regulatory
sequence analysis tools. Nucleic acids research, 36(Web Server issue),
W119--W127. <https://doi.org/10.1093/nar/gkn304>

Wasserman, W., Sandelin, A (2004). Applied bioinformatics for the
identification of regulatory elements. Nat Rev Genet 5, 276--287.
<https://doi.org/10.1038/nrg1315>

Zach. (2021) The Bonferroni Correction: Definition and Example.
Statology Org.
<https://www.statology.org/bonferroni-correction/#>:\~:text=For%20example%2C%20if%20we%20perform,01667.&text=Thus%2C%20we%20should%20only%20reject,the%20test%20is%20less%20than%20.

matrix-scan: <http://rsat.sb-roscoff.fr/help.matrix-scan.html>

bedops 2.4.20 :
<https://bedops.readthedocs.io/en/latest/content/reference/set-operations/bedops.html>

JASPAR 2022: <https://jaspar.genereg.net/>

RSAT Metazoa: <http://rsat.sb-roscoff.fr/tutorials.php>

Rsat matrix-scan output file format documentation:
<http://www.ra.cs.uni-tuebingen.de/software/ModuleMaster/doc/html/node6.html>

deeptools 2.5.3: <https://deeptools.readthedocs.io/en/develop/>

liftOver: <https://genome.ucsc.edu/cgi-bin/hgLiftOver>
